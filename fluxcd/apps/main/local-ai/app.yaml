---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: go-skynet
  namespace: flux-system
spec:
  interval: 1h0m0s
  type: default
  url: https://go-skynet.github.io/helm-charts/
---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: local-ai
  namespace: flux-system
spec:
  chart:
    spec:
      chart: local-ai
      sourceRef:
        kind: HelmRepository
        name: go-skynet
  interval: 1h0m0s
  targetNamespace: local-ai
  install:
    createNamespace: true
  values:
    replicaCount: 1
    deployment:
      env:
        threads: 4
        context_size: 1024
    nodeSelector:
      node-role: worker
      node-type: highmem
    models:
      list:
        - url: "https://gpt4all.io/models/ggml-gpt4all-j.bin"
        - url: "https://huggingface.co/TheBloke/Luna-AI-Llama2-Uncensored-GGUF/blob/main/luna-ai-llama2-uncensored.Q4_0.gguf"
        - url: "https://huggingface.co/TheBloke/Redmond-Puffin-13B-GGUF/raw/main/redmond-puffin-13b.Q8_0.gguf"
      persistence:
        pvc:
          enabled: true
          size: 64Gi
          accessModes:
          - ReadWriteMany
          storageClass: "longhorn"
    # Prompt templates to include
    # Note: the keys of this map will be the names of the prompt template files
    promptTemplates:
      ggml-gpt4all-j.tmpl: |
        The prompt below is a question to answer, a task to complete, or a conversation to respond to; decide which and write an appropriate response.
        ### Prompt:
        {{.Input}}
        ### Response:
      luna-ai-llama2-uncensored.Q4_0.tmpl: |
        USER: {{.Input}}
        ASSISTANT:
      redmond-puffin-13b.Q8_0.tmpl: |
        ### human: {{.Input}}
        ### response:
    ingress:
      enabled: true
      className: traefik
      hosts:
        - host: localai.main.k8s.2811rrt.net
          paths:
            - path: /
              pathType: Prefix
      tls: []